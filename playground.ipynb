{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cd68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# training_data_path = \"/scratch/data/open_teach/processed_data_pkl/grab_ball.pkl\"\n",
    "\n",
    "# with open(training_data_path, \"rb\") as f:\n",
    "#     training_data = pickle.load(f)\n",
    "\n",
    "# from pathlib import Path\n",
    "# import imageio\n",
    "\n",
    "# training_data.keys() # ['observations', 'max_cartesian', 'min_cartesian', 'max_gripper', 'min_gripper', 'task_emb']\n",
    "\n",
    "# demo_num = 0\n",
    "\n",
    "# max_cartesian = training_data['max_cartesian']\n",
    "# min_cartesian = training_data['min_cartesian']\n",
    "# max_gripper = training_data['max_gripper']\n",
    "# min_gripper = training_data['min_gripper']\n",
    "\n",
    "# print(f\"max_cartesian: {max_cartesian}\\nmin_cartesian: {min_cartesian}\")\n",
    "# len(training_data['observations']) # 100\n",
    "\n",
    "# training_data['observations'][demo_num].keys() # ['demo_dir', 'pixels0', 'cartesian_states', 'gripper_states']\n",
    "\n",
    "# cartesian_states = training_data['observations'][demo_num]['cartesian_states']\n",
    "# gripper_states = training_data['observations'][demo_num]['gripper_states']\n",
    "\n",
    "# frames = training_data['observations'][demo_num]['pixels0'][..., ::-1]\n",
    "# video_path = Path(f\"/home/danny/Downloads/demo_{demo_num}.mp4\")\n",
    "# video_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "# imageio.mimsave(video_path, frames, fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9d5fd",
   "metadata": {},
   "source": [
    "## Replay from Dataset sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a97ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /scratch/data/open_teach/processed_data_pkl/grab_ball.pkl\n"
     ]
    }
   ],
   "source": [
    "# preprocess the actions\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "from p3po.read_data.p3po_xarm import BCDataset, get_relative_action, get_quaternion_orientation\n",
    "\n",
    "path = \"/scratch/data/open_teach/processed_data_pkl\"\n",
    "processed_path = \"./processed_data\"\n",
    "tasks = [\"grab_ball\"]\n",
    "num_demos_per_task = 100\n",
    "obs_type = \"features\"\n",
    "history = True\n",
    "history_len = 10\n",
    "prompt =  \"text\"\n",
    "temporal_agg = True\n",
    "num_future_actions = 10\n",
    "img_size = 128 # should not matter\n",
    "action_after_steps = 1\n",
    "intermediate_goal_step = 30\n",
    "store_actions = True\n",
    "training_keys = [\"graph\"]\n",
    "subsample = 1\n",
    "skip_first_n = 0\n",
    "relative_actions = True\n",
    "\n",
    "dataset = BCDataset(\n",
    "    path=path,\n",
    "    processed_path=processed_path,\n",
    "    tasks=tasks,\n",
    "    num_demos_per_task=num_demos_per_task,\n",
    "    obs_type=obs_type,\n",
    "    history=history,\n",
    "    history_len=history_len,\n",
    "    prompt=prompt,\n",
    "    temporal_agg=temporal_agg,\n",
    "    num_future_actions=num_future_actions,\n",
    "    img_size=img_size,\n",
    "    action_after_steps=action_after_steps,\n",
    "    intermediate_goal_step=intermediate_goal_step,\n",
    "    store_actions=store_actions,\n",
    "    training_keys=training_keys,\n",
    "    subsample=subsample,\n",
    "    skip_first_n=skip_first_n,\n",
    "    relative_actions=relative_actions,\n",
    "    use_quaternion_orientation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    }
   ],
   "source": [
    "from dm_env import specs\n",
    "import pickle\n",
    "import numpy as np\n",
    "from p3po.replay_buffer import make_expert_replay_loader\n",
    "\n",
    "action_spec = specs.BoundedArray(\n",
    "    (dataset._max_action_dim,),\n",
    "    np.float32,\n",
    "    dataset.stats[\"actions\"][\"min\"],\n",
    "    dataset.stats[\"actions\"][\"max\"],\n",
    "    \"action\",\n",
    ")\n",
    "\n",
    "batch_size=1 # actual training used 64\n",
    "expert_replay_loader = make_expert_replay_loader(dataset, batch_size=batch_size)\n",
    "sample = next(iter(expert_replay_loader))\n",
    "stats = expert_replay_loader.dataset.stats # stats passed to agent act function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = sample[\"actions\"]\n",
    "proprioceptive = sample[\"proprioceptive\"]\n",
    "graph = sample[\"graph\"]\n",
    "\n",
    "# shape: B x history_len x? x action_dim\n",
    "actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eceabcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of episodes: 65\n",
      "dict_keys(['observation', 'action', 'task_emb'])\n",
      "Value(False)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "task_idx = 0\n",
    "_keys = dataset._keys\n",
    "_history_len = dataset._history_len\n",
    "\n",
    "episodes = dataset._episodes[task_idx]\n",
    "n_episodes = len(episodes)\n",
    "print(f\"Length of episodes: {n_episodes}\")\n",
    "episode_one = episodes[0]\n",
    "print(episode_one.keys())\n",
    "\n",
    "action = episode_one[\"action\"] # 170x7\n",
    "observations = episode_one[\"observation\"]\n",
    "gripper_states = episode_one[\"observation\"][\"gripper_states\"] # 170\n",
    "cartesian_states = episode_one[\"observation\"][\"cartesian_states\"] #  170x7\n",
    "graph = episode_one[\"observation\"][\"graph\"] # 170x60\n",
    "\n",
    "actions = episode_one[\"action\"]\n",
    "\n",
    "task_emb = 0\n",
    "\n",
    "sample_idx = np.random.randint(\n",
    "    0, len(observations[_keys[0]]) - _history_len\n",
    ")\n",
    "sampled_input = {}\n",
    "\n",
    "\n",
    "sampled_input = {}\n",
    "for key in _keys:\n",
    "    sampled_input[key] = observations[key][\n",
    "        sample_idx : sample_idx + dataset._history_len\n",
    "    ]\n",
    "\n",
    "start_idx = sample_idx\n",
    "end_idx = sample_idx + _history_len\n",
    "\n",
    "# combine cartesian states and gripper states\n",
    "cartesian_states = observations[\"cartesian_states\"][start_idx : end_idx]\n",
    "gripper_states = observations[\"gripper_states\"][start_idx : end_idx][:, None]\n",
    "\n",
    "sampled_proprioceptive_state = np.concatenate(\n",
    "    [cartesian_states, gripper_states],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "if dataset._temporal_agg:\n",
    "    # arrange sampled action to be of shape (history_len, num_queries, action_dim)\n",
    "    sampled_action = np.zeros(\n",
    "        (dataset._history_len, dataset._num_future_actions, actions.shape[-1])\n",
    "    )\n",
    "\n",
    "    # -1 since its num_queries including the last action of the history\n",
    "    # the target number of actions we want, but we might not be able to get\n",
    "    n_actions_needed = (dataset._history_len + dataset._num_future_actions - 1)\n",
    "    act = np.zeros((n_actions_needed, actions.shape[-1]))\n",
    "\n",
    "    # extract n_actions_needed actions starting at start idx.\n",
    "    avail_actions = min(len(actions), start_idx + n_actions_needed)\n",
    "    act[: avail_actions - start_idx] = actions[\n",
    "        start_idx : start_idx + n_actions_needed\n",
    "    ]\n",
    "\n",
    "    # pad with last action if we didn't have enough\n",
    "    if len(actions) < start_idx + n_actions_needed:\n",
    "        act[len(actions) - start_idx :] = actions[-1]\n",
    "\n",
    "    # overlap actions\n",
    "    sampled_action = np.lib.stride_tricks.sliding_window_view(\n",
    "        act, (dataset._num_future_actions, actions.shape[-1])\n",
    "    )\n",
    "    sampled_action = sampled_action[:, 0]\n",
    "else:\n",
    "    sampled_action = actions[start_idx : start_idx + dataset._history_len]\n",
    "\n",
    "return_dict = {}\n",
    "for key in dataset._keys:\n",
    "    return_dict[key] = sampled_input[key]\n",
    "return_dict[\"proprioceptive\"] = dataset.preprocess[\"proprioceptive\"](\n",
    "    sampled_proprioceptive_state\n",
    ")\n",
    "return_dict[\"actions\"] = dataset.preprocess[\"actions\"](sampled_action)\n",
    "return_dict[\"task_emb\"] = task_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fcbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 10, 7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(19*7).reshape((19, 7))\n",
    "\n",
    "# x is: [0 1 2 3 4 5]\n",
    "\n",
    "\n",
    "# Create a sliding window view with a window size of 3\n",
    "(num_future_actions, actions.shape[-1]) # 10 x 7\n",
    "v = np.lib.stride_tricks.sliding_window_view(x, (num_future_actions, actions.shape[-1]))\n",
    "# v is:\n",
    "# [[0 1 2]\n",
    "#  [1 2 3]\n",
    "#  [2 3 4]\n",
    "#  [3 4 5]]\n",
    "\n",
    "# Calculate the moving average\n",
    "# moving_average = v.mean(axis=-1)\n",
    "# # moving_average is: [1. 2. 3. 4.]\n",
    "# print(v)\n",
    "# print(moving_average)\n",
    "\n",
    "v.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3po",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
